# ğŸ“Š Retail Intelligence RAG Pipeline using LlamaIndex + Gemini

## ğŸš€ Project Overview

This project demonstrates a production-style **Retrieval-Augmented Generation (RAG)** pipeline built on structured retail transaction data.

The goal is to:

- Preprocess structured business data
- Convert tabular rows into semantic documents
- Build a vector index
- Enable natural language querying over business data
- Combine numerical reasoning + semantic retrieval
- Orchestrate a full LLM-powered analytics pipeline

This project showcases:

- Data Engineering
- LLM Orchestration
- RAG Architecture
- Vector Indexing
- Query Routing
- Hybrid Analytics (Structured + Semantic)

This is designed as a strong portfolio project for Data Analyst / AI / GenAI roles.

---

# ğŸ— Architecture Overview

```
Dataset (Excel)
        â†“
Preprocessing & Feature Engineering
        â†“
Structured DataFrame
        â†“
Document Creation (Row â†’ Text)
        â†“
Embedding Generation (Gemini)
        â†“
Vector Index (SimpleVectorStore)
        â†“
Query Routing
   â”œâ”€â”€ PandasQueryEngine (Numeric questions)
   â””â”€â”€ RAG Retriever (Semantic questions)
        â†“
LLM (Gemini Flash)
        â†“
Final Answer
```

---

# ğŸ“‚ Project Structure

```
llamaindex-retail-rag/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ online_retail.xlsx
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ build_index.py
â”‚   â”œâ”€â”€ query_engine.py
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ“ File-by-File Explanation

---

## 1ï¸âƒ£ `config.py`

Central configuration file.

Defines:
- Dataset path
- Gemini LLM model
- Gemini embedding model
- API key loading
- Retrieval parameters
- Index row limits

Why centralized config?
- Clean separation of logic and settings
- Easier scaling
- Professional project structure

---

## 2ï¸âƒ£ `preprocess.py`

Handles:

### âœ” Data Cleaning
- Removes cancelled invoices
- Removes invalid quantities
- Drops missing CustomerID
- Fixes data types

### âœ” Feature Engineering
- Revenue column
- YearMonth column
- Datetime conversion

### âœ” KPI Computation
- Total revenue
- Top country by revenue
- Monthly revenue aggregation

Why this step?

LLMs cannot work directly with raw tabular noise.
We must:
- Clean
- Structure
- Engineer meaningful business features

This shows real Data Analyst thinking.

---

## 3ï¸âƒ£ `build_index.py`

Core RAG builder.

### Step 1 â€” Convert rows into semantic documents

Each row becomes:

```
Invoice 12345 from UK on 2011-12-01.
Product: White Mug.
Quantity: 12.
Unit Price: 2.55.
Revenue: 30.60.
Customer ID: 17850.
```

Why?

LLMs understand natural language better than raw tables.

---

### Step 2 â€” Build Vector Index

Uses:

- `SimpleVectorStore` (in-memory)
- Gemini embeddings
- VectorStoreIndex

Why SimpleVectorStore?

- No external DB required
- Zero configuration
- Clean for portfolio use
- Avoids deployment complexity

---

## 4ï¸âƒ£ `query_engine.py`

Implements **Hybrid Query Routing**.

We detect query type:

### Numeric Query
Example:
- "What is total revenue?"
- "Which country generated highest revenue?"

â†’ Routed to `PandasQueryEngine`
â†’ Executes actual dataframe computation

---

### Semantic Query
Example:
- "Describe purchasing behavior in UK"
- "What kind of products are popular?"

â†’ Routed to RAG retriever
â†’ Retrieves relevant invoice rows
â†’ LLM generates contextual explanation

---

This hybrid architecture is powerful because:

- Numeric accuracy comes from Pandas
- Contextual reasoning comes from RAG
- We avoid hallucinated numbers

This is production-level thinking.

---

## 5ï¸âƒ£ `main.py`

Orchestrates entire pipeline.

Steps:

1. Initialize Gemini
2. Load dataset
3. Preprocess data
4. Compute KPIs
5. Create documents
6. Build vector index
7. Build query engines
8. Accept user queries
9. Route intelligently
10. Return response

This file ties everything together.

---

# ğŸ§  Why This Approach Was Chosen

### 1ï¸âƒ£ Demonstrates Real-World Pipeline

Not just LLM calls.
Not just Pandas.
But orchestration between:

- Data Engineering
- Retrieval
- Embeddings
- Query routing
- Generation

---

### 2ï¸âƒ£ Shows Understanding of RAG

Instead of blindly using an LLM,
we:

- Convert structured data â†’ semantic documents
- Index embeddings
- Retrieve relevant context
- Inject context into LLM

This prevents hallucination and improves reasoning.

---

### 3ï¸âƒ£ Hybrid Analytics = Edge Over Competitors

Most candidates:

- Either use Pandas
- Or use LLM

Very few combine both properly.

This project demonstrates:

âœ” Controlled LLM usage  
âœ” Numeric reliability  
âœ” Semantic intelligence  
âœ” Engineering discipline  

---

### 4ï¸âƒ£ Modular Design

Each file has single responsibility.

This shows:

- Clean code practices
- Separation of concerns
- Scalable design

---

# ğŸ’¡ Example Queries

Numeric:

- "What is the total revenue?"
- "Which country generated the highest revenue?"
- "Show monthly revenue trends."

Semantic:

- "Describe UK customer purchasing patterns."
- "What type of products sell most frequently?"
- "What insights can you derive from recent transactions?"

---

# ğŸ”¥ Technologies Used

- Python
- Pandas
- LlamaIndex
- Gemini API
- Vector Embeddings
- RAG Architecture
- dotenv
- Modular project structure

---

# âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 3ï¸âƒ£ Create `.env`

```
GOOGLE_API_KEY=your_api_key_here
```

### 4ï¸âƒ£ Run

```
python src/main.py
```

---

# ğŸ“ˆ Business Use Cases

This architecture can be extended for:

- Customer behavior analysis
- Business intelligence dashboards
- Financial audit assistants
- Sales analytics copilots
- Automated reporting agents
- Executive decision support systems

---

# ğŸ† Why This Is Resume-Worthy

This project demonstrates:

- Understanding of LLM internals
- Knowledge of embedding pipelines
- RAG architecture implementation
- Hybrid data systems
- Error handling & debugging
- Quota management awareness
- Clean modular engineering

This goes far beyond:

"Built a chatbot."

This shows:

"I can design AI systems."

---

# ğŸš€ Future Improvements

- Add Streamlit UI
- Add evaluation metrics
- Add caching layer
- Add persistent vector DB (FAISS / Chroma)
- Add batch embedding pipeline
- Add monitoring + logging
- Add API endpoint for production

---

# ğŸ“Œ Final Summary

This project transforms structured retail data into an intelligent conversational analytics system using:

- Data preprocessing
- Semantic indexing
- Hybrid query routing
- Gemini LLM reasoning
- Modular pipeline design

It demonstrates real-world LLM orchestration and applied AI engineering suitable for Data Analyst, AI Engineer, or GenAI roles.

---

**Author:** Krishna  
**Focus:** Data + AI + LLM Systems  
**Architecture:** Hybrid RAG + Structured Analytics  
